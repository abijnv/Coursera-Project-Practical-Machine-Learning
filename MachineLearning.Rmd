---
Title: "Human Activity Recognition - A Project in Machine Learning"
**Output**: HTML_document
**Author**: Durgaprasad K N
**Date**: July 16, 2016
---


##Executive Summary
####The purpose of this project is to fuflfil the requirements of of write up and submission of Practical Machine Learning Course on Coursera. 

A Random Forest Model is built on the data from [Groupware@LES Human Activity Recognition]( http://groupware.les.inf.puc-rio.br/har) to predict how well an activity is performed.

The HAR dataset  contains data collected from accelerometer and gyroscope for 6 subjects.

The Random Forest Model developed was able to predict the outcomes on the Validation sample with 99.34% accuracy with sensitivity and specificity of well above 97% for all the classes

##Input Data
Training & testing datasets are loaded from [Groupware@LES Human Activity Recognition](http://groupware.les.inf.puc-rio.br/har).

###Set the required Libraries
```{r}
library(caret)
library(rpart)
library(rattle)

```


###Setting the working directory for the code
```{r}
setwd("E:/Study/MachineLearning-R/Project")
```

###Creating the Initial dataset from CSV file
While reading the csv files itselfall missing values and errors were marked out so thatthese values could beeliminated from the analysis
```{r}
training_data = read.csv("pml-training.csv",na.strings=c("NA","#DIV/0!",""))
testing_data=read.csv("pml-testing.csv",na.strings=c("NA","#DIV/0!",""))
```
###Preprocessing of data
All information that was not relevant for analysis like names of the subjects, formats of the timestamp from the sensors were removed in this step. The first 7 columns of the data were found not relevant to the analysis
```{r}
training_data<-training_data[,-c(1:7)]
testing_data<-testing_data[,-c(1:7)]
```

###Missing value Treatment
The code taken from the [link] (https://gist.github.com/stephenturner/841686)  was used to calculate the missing value proportion in the training data. 
```{r}
propmiss <- function(dataframe) {
  m <- sapply(dataframe, function(x) {
    data.frame(
      nmiss=sum(is.na(x)), 
      n=length(x), 
      propmiss=sum(is.na(x))/length(x)
    )
  })
  d <- data.frame(t(m))
  d <- sapply(d, unlist)
  d <- as.data.frame(d)
  d$variable <- row.names(d)
  row.names(d) <- NULL
  d <- cbind(d[ncol(d)],d[-ncol(d)])
  return(d[order(d$propmiss), ])
}
```



####The proportion of missing values so computed was used to remove columns with more than 30% missing values
```{r}
pmiss<-propmiss(training_data)
mcols<-subset(pmiss$variable,pmiss$nmiss<0.3)
```
####The variables with missing vlaues were removed from the training as well as the testing dataset
```{r}
dTraining<-training_data[,mcols]

#Making the testing Data same as the training data
dTesting<-testing_data[,names(testing_data) %in% names(dTraining)]

```
##Partitioning Training Data
The training data was partition in the Development and the Validation dataset based on simple random sampling stratified by variable "classe"
```{r}
#Setting seed for reproducibility of results
set.seed(1682)

#Creating Partition of Training Data based on Simple Random Sampling Stratified by classe
sampTrain<-createDataPartition(training_data$classe,p=0.7,list=FALSE)
subDev<-dTraining[sampTrain,]
subVal<-dTraining[-sampTrain,]
```

##Initial Model
Since the response/target variable is a class variable, as a first step Decision Tree model was tried
```{r}
modFitIni<-train(classe~.,method="rpart",data=subDev)
modFitIni
#Testing the Calssification Tree Model
confusionMatrix(predict(modFitIni,subVal),subVal$classe)
```
This model gave an accuracy of 49%.

##Final Model
The Final Model was created using the Random Forest technique. This model has lower bias and is one of the most accurate techniqe where the problem involvess classification.
```{r}
set.seed(1682)
modFit<-train(classe~.,method="rf",data=subDev)
```

The model parameters were tested on the validation dataset.
```{r}
confusionMatrix(predict(modFit,subVal),subVal$classe)
```
##Submission
The outcome predicted on the testing data using Random Forest algorithm
```{r}
#Fitting the model on the Test dataset
predFinal<-predict(modFit,testing_data)
predFinal
```






